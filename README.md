# Adversarial_attack

Voici le dépôt github de notre projet de MLA. 
Nous avons étudié l'article "Explaining and Harnessing Adversarial Examples" qui traite des fameuses adversarial attacks.
Cet article propose une approche afin d'expliquer l'origine de l'effet de ces attaques et tente par la suite de prouver cette thèse par un ensemble d'expériences mettant en lumière l'application d'attaques adversarial sur différents types de modèles de clasiffication d'image en se basant sur le dataset MNIST.


## Répartition des tâches

***1 fast gradient sign method ***
